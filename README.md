### Abstract

We aim to implement a Neural Network system for generating the speech corresponding to a piece of text, with a small caveat: the generated speech should be directed towards an input emotion, such as angry, sad, happy, shocked etc. The preliminary idea is to join two networks: the first one for a general text to speech conversion and the second one for adding emotions to the waveform output by the first network.

### Team

1. Drumil Trivedi
2. Maitrey Gandopadhye
3. Gurparkash Singh

### References

## Text to Speech Papers
1. [Tacotron 2 (Blog)](https://ai.googleblog.com/2017/12/tacotron-2-generating-human-like-speech.html)
2. [Tacotron 2 (Paper)](https://arxiv.org/pdf/1712.05884.pdf)
3. [Tacotron 1 (Paper)](https://arxiv.org/abs/1703.10135)
4. [Wavenet (Blog)](https://deepmind.com/blog/article/wavenet-generative-model-raw-audio)
5. [Wavenet (Paper)](https://arxiv.org/pdf/1609.03499.pdf)

## Conditioned Speech Conversion
1. [Nonparallel Emotional Speech Conversion](https://arxiv.org/pdf/1811.01174.pdf)

## Alternate Project
1. [Voice Impersonation using GANs](https://arxiv.org/pdf/1802.06840.pdf)

## Datasets